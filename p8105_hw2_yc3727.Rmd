---
title: "Homework 2"
author: Chloe Chah
output: github_document
editor_options: 
  chunk_output_type: console
---



```{r}
library(tidyverse)
library(readxl)
```

## Problem 1 

#### Read the Mr.Trashwheel dataset. 

```{r}

trashwheel_df = 
  read_xlsx(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "Mr. Trash Wheel",
    range = cell_cols("A:N")) %>% 
  janitor::clean_names() %>%
  drop_na(dumpster) %>%
  mutate(
    sports_balls = round(sports_balls), 
    sports_balls = as.integer(sports_balls)
  )
```

#### Read precipitation data! 

```{r}
  precip_2018 = 
   read_excel(
     "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx", 
     sheet = "2018 Precipitation", 
     skip = 1
   ) %>% 
  janitor::clean_names() %>%
  drop_na(month) %>%
  mutate(year = 2018) %>%
  relocate(year)

precip_2017 = 
  read_excel(
     "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx", 
     sheet = "2017 Precipitation", 
     skip = 1
   ) %>% 
  janitor::clean_names() %>%
  drop_na(month) %>%
  mutate(year = 2017) %>%
  relocate(year)

```

#### Now combine annual precipitation.

```{r}
  month_df = 
    tibble(
      month = 1:12, 
      month_name = month.name
    )
  
  precip_df = 
    bind_rows(precip_2018, precip_2017)
  
  left_join(precip_df, month_df, by = "month")

```

* This dataset contains information from the Mr. Trashwheel trash collector in Baltimore, Maryland. As trash enters the inner harbor, the trashwheel collects that trash and stores it in a dumpster. 
* The dataset contains information on year, month, and trash collected, including some specific kinds of trash. There are a total of `r nrow(trashwheel_df)` rows in our final dataset. Additional data sheets include monthly precipitation data. 
* The total precipitation in 2018 is `r select(precip_2018, total) %>% sum()`. 
* The median number of sports balls in 2017 is `r median(filter(trashwheel_df, year == 2017)$sports_balls)`.

## Problem 2 

#### Read in csv file, clean variable names, convert entry variable, reformat route columns 

```{r}
   transit_df = read_csv(
     "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>%
    janitor::clean_names() %>%
    select(line:entry, vending, ada) %>%
    #mutate(entry = ifelse(entry == "YES", "True", "False"))
    mutate(entry = recode(entry, "YES" = TRUE, "NO" = FALSE)) %>%
    mutate(
      route8 = as.character(route8), 
      route9 = as.character(route9), 
      route10 = as.character(route10), 
      route11 = as.character(route11)) %>%
    pivot_longer(
      route1:route11, 
      names_to = "route_number", 
      values_to = "route_name", 
      names_prefix = "route"
    )
```

#### Description of the NYC Transit dataset 

* The dataset contains information related to each entrance and exit for each subway station in New York City. 
* It contains the following variables: `r ls(transit_df)`. 
* The dataset has `r nrow(transit_df)` rows and `r ncol(transit_df)` columns. 
* In terms of the data cleaning steps, I first read the csv file into R, used the clean_names() function to clean the variable names. Then I used the select function to retain only the desired variables. I've also converted the entry variable from a character variable to a logical variable.
* This dataset was not tidy because there were redundant columns that seem to describe the same thing (e.g. route information is spread across 11 columns) so I reformatted the route columns. 

#### Next questions about the NYC transit data

```{r}
  distinct_transit_df = 
    distinct(transit_df, line, station_name, .keep_all = TRUE) 
  
```

* There are `r nrow(distinct_transit_df)` distinct stations. 
* There are `r nrow(filter(distinct_transit_df, ada == TRUE))` stations that are ADA compliant.
* `r nrow(filter(transit_df, vending == "NO", entry == TRUE))` out of `r nrow(filter(transit_df, vending == "NO"))` station entrances/exits without vending allow entrance. 
* There are `r nrow(filter(distinct_transit_df, route_name == "A"))` distinct stations that serve train A.
* There are `r nrow(filter(distinct_transit_df, route_name == "A", ada ==TRUE))` stations that serve the A train and are also ADA compliant. 

## Problem 3 

#### Reading in & cleaning data; breaking up mon variable; replacing month number with month name; creating a president variable; deleting prez_dem, prez_gop, & day variable; 

```{r}
pols_df = read_csv(
    "./data/pols-month.csv") %>%
    janitor::clean_names() %>%
    separate(mon, sep = "-", into = c("year", "month", "day")) %>%
    mutate(year = as.integer(year)) %>%
    mutate(month = as.integer(month)) %>%
    mutate(day = as.integer(day))

month_df = 
    tibble(
        month = 1:12,
        month_name = month.abb)

pols_df =
    left_join(pols_df, month_df, by = "month") %>%
    relocate(month_name, .after = "month") %>%
    mutate(
      president = ifelse(prez_gop == "1", "gop", "dem")) %>%
    relocate(president, .after = "month_name")

pols_df = select(pols_df, -day, -prez_dem, -prez_gop, -month)

pols_df

```


#### Cleaning the data in snp.csv using a similar process to the above; Arranging according to year and month; organizing so that year and month are the leading columns.

```{r}

snp_df = read_csv(
    "./data/snp.csv") %>%
    janitor::clean_names() %>%
    separate(date, sep = "/", into = c("month", "day", "year")) %>%
    mutate(year = as.integer(year)) %>%
    mutate(month = as.integer(month)) %>%
    mutate(day = as.integer(day)) 

month_df = 
    tibble(
        month = 1:12,
        month_name = month.abb)

snp_df =
    left_join(snp_df, month_df, by = "month") %>%
    subset(select = -c(day,month)) %>%
    relocate(year, month_name)

snp_df
```

#### Tidying the unemployment data so that it can be merged with the previous datasets.

```{r}

  unemp_df = read_csv(
    "./data/unemployment.csv") %>%
    janitor::clean_names()

  unemp_tidy_df = 
    pivot_longer(
      unemp_df, 
      jan:dec, 
      names_to = "month",
      values_to = "unemployment"
    ) %>%
    mutate(year = as.integer(year))

  unemp_tidy_df
  
```

#### Join the datasets by merging snp into pols, then merging unemployment into the result.

```{r}
  merged_snppols_df = 
    left_join(pols_df, snp_df, by = "year","month")

  merged_all_df = 
    left_join(merged_snppols_df, unemp_tidy_df, by = "year","month")

  merged_all_df
```

#### Description of the datasets

* The pols-month dataset contains information related to the number of national politicians who are democratic or republican at any given time. 
* The snp dataset contains information related to Standard & Poorâ€™s stock market index (S&P) on a given date, often used as a representative measure of stock market as a whole.
* The unemployment dataset contains information related to the percentage of unemployment in a given month of a certain year. 
* The final merged dataset contains information from all of the aforementioned datsets above merged together by year and date through a left join function. The final dataset contains `r nrow(merged_all_df)` rows and `r ncol(merged_all_df)` columns. 
* The earliest year recorded in this dataset is `r min(merged_all_df$year)` and the most recent year recorded in this dataset is `r max(merged_all_df$year)`: covering a range of `r max(merged_all_df$year)-min(merged_all_df$year)` years. 
* It contains the following variables: `r ls(merged_all_df)`.


