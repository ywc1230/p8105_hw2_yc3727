---
title: "Homework 2"
author: "Chloe Chah"
output: github_document
---



```{r}
library(tidyverse)
library(readxl)
```

## Problem 1 

#### Read and clean the Mr.Trashwheel dataset. 

```{r}

trashwheel_df = 
  read_xlsx(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "Mr. Trash Wheel",
    range = cell_cols("A:N")) %>% 
  janitor::clean_names() %>%
  drop_na(dumpster) %>%
  mutate(
    sports_balls = round(sports_balls), 
    sports_balls = as.integer(sports_balls)
  )
```

#### Read and clean precipitation data! 

```{r}
  precip_2018 = 
   read_excel(
     "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx", 
     sheet = "2018 Precipitation", 
     skip = 1
   ) %>% 
  janitor::clean_names() %>%
  drop_na(month) %>%
  mutate(year = 2018) %>%
  relocate(year)

precip_2017 = 
  read_excel(
     "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx", 
     sheet = "2017 Precipitation", 
     skip = 1
   ) %>% 
  janitor::clean_names() %>%
  drop_na(month) %>%
  mutate(year = 2017) %>%
  relocate(year)

```

#### Now combine annual precipitation dataset.

```{r}
  month_df = 
    tibble(
      month = 1:12, 
      month_name = month.name
    )
  
  precip_df = 
    bind_rows(precip_2018, precip_2017)
  
  left_join(precip_df, month_df, by = "month")

```

* This dataset contains information from the Mr. Trashwheel trash collector in Baltimore, Maryland. As trash enters the inner harbor, the trashwheel collects that trash and stores it in a dumpster. 
* The Trashwheel dataset contains important variables on year, month, and weight and volume of trash collected, including some specific kinds of trash. The Trashwheel dataset has `r nrow(trashwheel_df)` rows or observations and contains the following variables: `r ls(trashwheel_df)`.  Additional data sheets include monthly precipitation data. 
* There are a total of `r nrow(precip_df)` rows in our final combined precipitation dataset from 2017 and 2018. The final combined precipitation dataset includes variables on the year and month of the measurement of precipitation and the total amount of precipitation during that specific time period in inches. 
* The total precipitation in 2018 is `r select(precip_2018, total) %>% sum()` inches. 
* The median number of sports balls in 2017 is `r median(filter(trashwheel_df, year == 2017)$sports_balls)`.

## Problem 2 

#### Read in csv file, clean variable names, convert entry variable, reformat route columns 

```{r}
   transit_df = read_csv(
     "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>%
    janitor::clean_names() %>%
    select(line:entry, vending, ada) %>%
    mutate(entry = recode(entry, "YES" = TRUE, "NO" = FALSE)) %>%
    mutate(
      route8 = as.character(route8), 
      route9 = as.character(route9), 
      route10 = as.character(route10), 
      route11 = as.character(route11)) %>%
    pivot_longer(
      route1:route11, 
      names_to = "route_name", 
      values_to = "route_number", 
      names_prefix = "route",
    )
```

#### Description of the NYC Transit dataset 

* The **transit** dataset contains information related to each entrance and exit for each subway station in New York City. I modified the dataset to include information on the line, station, name, station latitude/longitude, routes served, entry, vending, entrance type, and ADA compliance.
* It contains the following variables: `r ls(transit_df)`. 
* The dimension of the dataset is `r dim(transit_df)` in that the dataset has `r nrow(transit_df)` rows and `r ncol(transit_df)` columns.  
* In terms of the data cleaning steps, I first read the csv file into R, used the clean_names() function from the janitor package to clean the variable names. Then I used the select function to retain only the desired variables. I've also converted the entry variable from a character variable to a logical variable through a recode function. 
* This dataset was not tidy because there were redundant columns that seem to describe the same thing (e.g. route information was spread across 11 columns) so I reformatted the route columns through a pivot_longer function to save the route names (1-11) in a route_name variable and the corresponding letters and numbers in a route_number variable. 

#### Next questions about the NYC transit data

```{r}
#1: Number of distinct stations
  distinct_transit_df = 
    distinct(transit_df, line, station_name, .keep_all = TRUE) 
  nrow(distinct_transit_df)

#2: Number of ADA compliant stations
  nrow(filter(distinct_transit_df, ada == TRUE))
  
#3: Proportion of station entrances/exits without vending allow entrance
  no_vending = filter(transit_df, vending == "NO")
  nov_noe = filter(transit_df, vending == "NO", entry == TRUE)
  nrow(nov_noe)/nrow(no_vending)
  
#4: Number of stations that serve the A train 
 nrow(filter(distinct_transit_df, route_number == "A"))
 
#5: Number of ADA compliant stations that serve the A train
 nrow(filter(distinct_transit_df, route_number == "A", ada == TRUE))
 
```

* There are `r nrow(distinct_transit_df)` distinct stations. 
* There are `r nrow(filter(distinct_transit_df, ada == TRUE))` stations that are ADA compliant.
* `r nrow(filter(transit_df, vending == "NO", entry == TRUE))` out of `r nrow(filter(transit_df, vending == "NO"))` station entrances/exits without vending allow entrance. So the proportion of station entrances / exits without vending allow entrance is `r (nrow(filter(transit_df, vending == "NO", entry == TRUE)))/(nrow(filter(transit_df, vending == "NO")))*100` %.
* There are `r nrow(filter(distinct_transit_df, route_number == "A"))` distinct stations that serve train A.
* There are `r nrow(filter(distinct_transit_df, route_number == "A", ada ==TRUE))` stations that serve the A train and are also ADA compliant. 

## Problem 3 

#### Reading in & cleaning data; breaking up mon variable; replacing month number with month name; creating a president variable; deleting prez_dem, prez_gop, & day variable; 

```{r}
pols_df = read_csv(
    "./data/pols-month.csv") %>%
    janitor::clean_names() %>%
    separate(mon, sep = "-", into = c("year", "month", "day")) %>%
    mutate(year = as.integer(year)) %>%
    mutate(month = as.integer(month)) %>%
    mutate(day = as.integer(day))

month_df = 
    tibble(
        month = 1:12,
        month_name = month.abb)

pols_tidy_df =
    left_join(pols_df, month_df, by = "month") %>%
    mutate(president = ifelse(prez_gop == "1", "gop", "dem")) %>%
    mutate(month_name = toupper(month_name)) %>%
    relocate(year, month_name, president) %>%
    select(-day, -prez_dem, -prez_gop, -month)

head(pols_tidy_df)

```


#### Cleaning the data in snp.csv using a similar process to the above; Arranging according to year and month; organizing so that year and month are the leading columns.

```{r}

snp_df = read_csv(
    "./data/snp.csv") %>%
    janitor::clean_names() %>%
    separate(date, sep = "/", into = c("month", "day", "year")) %>%
    mutate(year = as.integer(year)) %>%
    mutate(month = as.integer(month)) %>%
    mutate(day = as.integer(day)) 

month_df = 
    tibble(
        month = 1:12,
        month_name = month.abb)

snp_tidy_df =
    left_join(snp_df, month_df, by = "month") %>%
    mutate(month = month_name) %>%
    mutate(month_name = toupper(month_name)) %>%
    relocate(year, month_name) %>%
    select(-day, -month)

head(snp_tidy_df)
```

#### Tidying the unemployment data so that it can be merged with the previous datasets.

```{r}

  unemp_df = read_csv(
    "./data/unemployment.csv") %>%
    janitor::clean_names()

  unemp_tidy_df = 
    pivot_longer(
      unemp_df, 
      jan:dec, 
      names_to = "month_name",
      values_to = "unemployment"
    ) %>%
    mutate(year = as.integer(year)) %>% 
    mutate(month_name = toupper(month_name)) %>%
    relocate(year, month_name) 

head(unemp_tidy_df)
  
```

#### Join the datasets by merging snp into pols, then merging unemployment into the result.

```{r}
  merged_snppols_df = 
    left_join(pols_tidy_df, snp_tidy_df, by = c("year", "month_name"))

  merged_all_df = 
    left_join(merged_snppols_df, unemp_tidy_df, by = c("year", "month_name")) 

  head(merged_all_df)
```

#### Description of the datasets

* The **pols-month** dataset contains information related to the number of national politicians who are democratic or republican at any given time. We modified the dataset to include year, month_name, president, gov_gop (number of republican governors), sen_gop (the number of republican senators), rep_gop (number of republican representatives), gov_dem, sen_dem, and rep_dem.  
* The **snp** dataset contains information related to Standard & Poorâ€™s stock market index (S&P) on a given date, often used as a representative measure of stock market as a whole. We modified the dataset to include year, month_name, and close. 
* The **unemployment** dataset contains information related to the percentage of unemployment in a given month of a certain year. We modified the dataset to include year, month_name, and percentage of unemployment.
* The **final merged dataset** (merged_all_df) contains information from the three aforementioned datsets above merged together by year and month through a left join function. The final dataset contains `r nrow(merged_all_df)` rows and `r ncol(merged_all_df)` columns. The final dataset has the following key variables: `r ls(merged_all_df)`.
* The earliest year recorded in this dataset is `r min(merged_all_df$year)` and the most recent year recorded in this dataset is `r max(merged_all_df$year)`: covering a range of `r max(merged_all_df$year)-min(merged_all_df$year)` years. 


